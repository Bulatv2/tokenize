# tokenize russian
tokenize to senteces, words, punctuation, use stop-words, lemmatize

requirements: module vector from my repository
